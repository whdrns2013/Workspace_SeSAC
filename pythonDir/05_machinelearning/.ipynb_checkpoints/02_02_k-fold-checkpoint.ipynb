{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dccfd67d-2f50-4053-a1cc-5102934967ae",
   "metadata": {},
   "source": [
    "# 정리할 것 / 숙제\n",
    "  \n",
    "* `count_values` : DataFrame 의 Value 값들의 분포 (개수)를 보여줌\n",
    "* 본 파일 정리 필요  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af086-abc9-4e57-9e26-b58e3f7d8f56",
   "metadata": {},
   "source": [
    "# K-fold  \n",
    "  \n",
    "> <strong>교차검증의 필요성</strong>  \n",
    "> * 훈련용 데이터와 실제 분석 데이터가 같게 되면 \"과대적합\"이 발생한다.  \n",
    "> * 훈련용 데이터에는 잘 예측하지만, 새로운 데이터에 대해서는 정확한 예측을 하지 못하는 경우를 말한다.  \n",
    "> * 이를 방지하기 위해 train data / test data로 나누어서 학습과 검증을 진행하지만  \n",
    "> * 이로써도 과대적합 문제가 해결되지 않을 수 있기에 데이터셋을 k개로 나눈 후 교차 검증을 하기도 한다.    \n",
    "  \n",
    "> <strong>K-fold</strong>  \n",
    "> * 데이터셋을 K 개로 나누어 서로 교차검증 (근데 왜 검증이라고 부르는거지?)  \n",
    "> * K개 중 K-1 개를 학습 데이터로, 나머지 (편의상 1번)을 검증용 데이터로 하여 결과값을 낸다.    \n",
    "> * K개 중 K-1 개를 학습 데이터로, 2번 데이터를 검증용으로 해 결과값을 낸다.  \n",
    "> * ... 이를 K 번 반복  \n",
    "> * K개 중 K-1 개를 학습 데이터로, K번 데이터를 검증용으로 해 결과값을 낸다.  \n",
    "> * 그러고 난 후, 이 모든 데이터를 평균을 낸 값을 최종 결과값으로 한다.  \n",
    "    \n",
    "> <strong>사용법</strong>   \n",
    "> * 라이브러리 : `sklearn.model_selection import KFold`  \n",
    "> * 옵션  \n",
    "> (1) n_split : 몇 개의 데이터셋으로 나눌지  \n",
    "> (2) shuffle : 원 데이터셋의 순서를 섞을지  \n",
    "> (3) random_state : 난수 생성 규칙 선택  \n",
    "> * 메서드  \n",
    "> (1) .split(데이터셋) : 데이터셋을 위에서 설정한 옵션에 맞게 분할한다.  \n",
    "> (2) .get_n_splits() : 앞의 Kfold 가 데이터셋을 몇 개로 나누는지 K 를 반환  \n",
    "> (3) .mro : ??? 모르겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ccc105-a2b4-450d-8886-d4c4a6874a0a",
   "metadata": {},
   "source": [
    "* import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc755272-e30e-4400-abb7-0a904ec7af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4bd27-982b-40c8-88b7-3ed5e71c73be",
   "metadata": {},
   "source": [
    "## K-Fold 기본 사용법  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a323c2-1227-464b-9c65-727f30b5245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 세팅\n",
    "# (1) 사용할 데이터 셋 세팅\n",
    "# (2) 사용할 머신러닝 모델 설정\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "## 의사결정나무 분류형 모델을 사용할 것임\n",
    "## random_state : 난수 생성 규칙 / =156 이면 156 번째 난수 생성 법칙을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69cd251b-18c5-49ad-aee5-dce4a7e5a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.9\n",
      "3 0.9333333333333333\n",
      "4 0.9666666666666667\n",
      "5 0.9\n"
     ]
    }
   ],
   "source": [
    "# K-fold 설정\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "## K-fold 설정 : 5번 Fold 하는 kfold 생성\n",
    "## shuffle : 데이터를 섞어줄지 말지 지정 (데이터 몰림 방지)\n",
    "\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "## 필요 변수 선언\n",
    "\n",
    "for train_index, test_index in kfold.split(iris.data):\n",
    "    #kfold(fold 저장값 5) 로 iris데이터셋을 나눈다.\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    dt_clf.fit(X_train, y_train) # X_train, y_train 데이터로 학습 진행\n",
    "    pred = dt_clf.predict(X_test)  # X_test 를 예측한다.\n",
    "    n_iter += 1\n",
    "    accuracy = accuracy_score(y_test, pred)  # y_test (타겟값 = 답) 과 pred(예측값)간 정확도 비교\n",
    "    cv_accuracy.append(accuracy)  # 각 회차별 정확도를 cv_accuracy 리스트에 저장\n",
    "    print(n_iter, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1108f9e9-7546-4e7f-be93-077e0c8e88cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(cv_accuracy), 4)\n",
    "# 5번 kfold 를 진행한 평균 정확도를 살펴보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e12603-48bb-47b6-ab4f-481caa93a775",
   "metadata": {},
   "source": [
    "## Stratified K - fold : 분산이 일정한 k-fold\n",
    "  \n",
    "* 불균형한 분포도를 가진 레이블 데이터 집합을  \n",
    "* 최대한 \"균등\" 한 fold 들로 나누기 위해 사용하는 폴드법  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9c1ff0e-3af3-4248-9ede-d328fe121617",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [[5.1, 3.5, 1.4, 0.2], [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5.0, 3.6, 1.4, 0.2], [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5.0, 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3.0, 1.4, 0.1], [4.3, 3.0, 1.1, 0.1], [5.8, 4.0, 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], [5.1, 3.5, 1.4, 0.3], [5.7, 3.8, 1.7, 0.3], [5.1, 3.8, 1.5, 0.3], [5.4, 3.4, 1.7, 0.2], [5.1, 3.7, 1.5, 0.4], [4.6, 3.6, 1.0, 0.2], [5.1, 3.3, 1.7, 0.5], [4.8, 3.4, 1.9, 0.2], [5.0, 3.0, 1.6, 0.2], [5.0, 3.4, 1.6, 0.4], [5.2, 3.5, 1.5, 0.2], [5.2, 3.4, 1.4, 0.2], [4.7, 3.2, 1.6, 0.2], [4.8, 3.1, 1.6, 0.2], [5.4, 3.4, 1.5, 0.4], [5.2, 4.1, 1.5, 0.1], [5.5, 4.2, 1.4, 0.2], [4.9, 3.1, 1.5, 0.2], [5.0, 3.2, 1.2, 0.2], [5.5, 3.5, 1.3, 0.2], [4.9, 3.6, 1.4, 0.1], [4.4, 3.0, 1.3, 0.2], [5.1, 3.4, 1.5, 0.2], [5.0, 3.5, 1.3, 0.3], [4.5, 2.3, 1.3, 0.3], [4.4, 3.2, 1.3, 0.2], [5.0, 3.5, 1.6, 0.6], [5.1, 3.8, 1.9, 0.4], [4.8, 3.0, 1.4, 0.3], [5.1, 3.8, 1.6, 0.2], [4.6, 3.2, 1.4, 0.2], [5.3, 3.7, 1.5, 0.2], [5.0, 3.3, 1.4, 0.2], [7.0, 3.2, 4.7, 1.4], [6.4, 3.2, 4.5, 1.5], [6.9, 3.1, 4.9, 1.5], [5.5, 2.3, 4.0, 1.3], [6.5, 2.8, 4.6, 1.5], [5.7, 2.8, 4.5, 1.3], [6.3, 3.3, 4.7, 1.6], [4.9, 2.4, 3.3, 1.0], [6.6, 2.9, 4.6, 1.3], [5.2, 2.7, 3.9, 1.4], [5.0, 2.0, 3.5, 1.0], [5.9, 3.0, 4.2, 1.5], [6.0, 2.2, 4.0, 1.0], [6.1, 2.9, 4.7, 1.4], [5.6, 2.9, 3.6, 1.3], [6.7, 3.1, 4.4, 1.4], [5.6, 3.0, 4.5, 1.5], [5.8, 2.7, 4.1, 1.0], [6.2, 2.2, 4.5, 1.5], [5.6, 2.5, 3.9, 1.1], [5.9, 3.2, 4.8, 1.8], [6.1, 2.8, 4.0, 1.3], [6.3, 2.5, 4.9, 1.5], [6.1, 2.8, 4.7, 1.2], [6.4, 2.9, 4.3, 1.3], [6.6, 3.0, 4.4, 1.4], [6.8, 2.8, 4.8, 1.4], [6.7, 3.0, 5.0, 1.7], [6.0, 2.9, 4.5, 1.5], [5.7, 2.6, 3.5, 1.0], [5.5, 2.4, 3.8, 1.1], [5.5, 2.4, 3.7, 1.0], [5.8, 2.7, 3.9, 1.2], [6.0, 2.7, 5.1, 1.6], [5.4, 3.0, 4.5, 1.5], [6.0, 3.4, 4.5, 1.6], [6.7, 3.1, 4.7, 1.5], [6.3, 2.3, 4.4, 1.3], [5.6, 3.0, 4.1, 1.3], [5.5, 2.5, 4.0, 1.3], [5.5, 2.6, 4.4, 1.2], [6.1, 3.0, 4.6, 1.4], [5.8, 2.6, 4.0, 1.2], [5.0, 2.3, 3.3, 1.0], [5.6, 2.7, 4.2, 1.3], [5.7, 3.0, 4.2, 1.2], [5.7, 2.9, 4.2, 1.3], [6.2, 2.9, 4.3, 1.3], [5.1, 2.5, 3.0, 1.1], [5.7, 2.8, 4.1, 1.3], ...], 'target': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], 'frame': None, 'target_names': ['setosa', 'versicolor', 'virginica'], 'DESCR': '.. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}    8\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       150 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 728.0 bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  150.000000\n",
       "mean     1.000000\n",
       "std      0.819232\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      2.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# st k-fold 를 사용하기 전에, 데이터셋을 한 번 살펴보자!\n",
    "import pandas as pd\n",
    "\n",
    "## 밸류값 출력\n",
    "print(pd.value_counts(iris)), print('\\n')\n",
    "print(pd.value_counts(iris.target))\n",
    "\n",
    "## 분산 보기\n",
    "irisnp = pd.DataFrame(iris.target)\n",
    "print(irisnp.info())\n",
    "irisnp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3187111f-1537-487b-a654-17c2506bf78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "2 0.9666666666666667\n",
      "3 0.8666666666666667\n",
      "4 0.9333333333333333\n",
      "5 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# (1) 그냥 k-fold without shuffle\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle=False)\n",
    "\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris.data):   #kfold(fold 저장값 5) 로 iris데이터셋을 나눈다 -> 5개의 데이터셋이 각각 다시 train과 test 데이터셋으로 분할된다.\n",
    "    # print(train_index)\n",
    "    # print(test_index)\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    dt_clf.fit(X_train, y_train) # 분석???\n",
    "    pred = dt_clf.predict(X_test)  # X_test 를 예측한다.\n",
    "    n_iter += 1\n",
    "    accuracy = accuracy_score(y_test, pred)  # y_test (타겟값 = 답) 과 pred(예측값)간 정확도 비교\n",
    "    cv_accuracy.append(accuracy)  # 각 회차별 정확도를 cv_accuracy 리스트에 저장\n",
    "    print(n_iter, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bda6ec1-0002-4ae8-8542-4a975f09f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9\n",
      "2 0.9333333333333333\n",
      "3 0.9333333333333333\n",
      "4 0.9666666666666667\n",
      "5 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# (2) 그냥 k-fold with shuffle\n",
    "# 위보다 더 정확도가 좋음을 볼 수 있다.\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris.data):   #kfold(fold 저장값 5) 로 iris데이터셋을 나눈다 -> 5개의 데이터셋이 각각 다시 train과 test 데이터셋으로 분할된다.\n",
    "    # print(train_index)\n",
    "    # print(test_index)\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    dt_clf.fit(X_train, y_train) # 분석???\n",
    "    pred = dt_clf.predict(X_test)  # X_test 를 예측한다.\n",
    "    n_iter += 1\n",
    "    accuracy = accuracy_score(y_test, pred)  # y_test (타겟값 = 답) 과 pred(예측값)간 정확도 비교\n",
    "    cv_accuracy.append(accuracy)  # 각 회차별 정확도를 cv_accuracy 리스트에 저장\n",
    "    print(n_iter, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9cf73ed7-be33-489a-a317-1f34e8f30083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 회차 0.9666666666666667\n",
      "학습데이터 분포:  0    40\n",
      "1    40\n",
      "2    40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "2 회차 0.9666666666666667\n",
      "학습데이터 분포:  0    40\n",
      "1    40\n",
      "2    40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "3 회차 0.9\n",
      "학습데이터 분포:  0    40\n",
      "1    40\n",
      "2    40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "4 회차 0.9666666666666667\n",
      "학습데이터 분포:  0    40\n",
      "1    40\n",
      "2    40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "5 회차 1.0\n",
      "학습데이터 분포:  0    40\n",
      "1    40\n",
      "2    40\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3) st k-fold\n",
    "# split 되는 데이터셋들이 비슷한 분포가 되도록 섞어 Fold 를 진행한다.\n",
    "# 더욱 더 높은 정확성을 보인다.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle=False)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris.data, iris.target):   \n",
    "    # print(train_index)\n",
    "    # print(test_index)\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train) # 분석???\n",
    "    pred = dt_clf.predict(X_test)  # X_test 를 예측한다.\n",
    "    n_iter += 1\n",
    "    accuracy = accuracy_score(y_test, pred)  # y_test (타겟값 = 답) 과 pred(예측값)간 정확도 비교\n",
    "    cv_accuracy.append(accuracy)  # 각 회차별 정확도를 cv_accuracy 리스트에 저장\n",
    "    \n",
    "    print(n_iter, \"회차\" , accuracy)\n",
    "    print(\"학습데이터 분포: \", pd.DataFrame(y_train).value_counts())  # 학습데이터 보기 : value_couts = 밸류값들을 카운트해 보여준다 (분포 보기 좋음)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cab32-4f9e-4af8-82ba-0ee7f838cf2a",
   "metadata": {},
   "source": [
    "## cross_val_score() 교차검증을 간편하게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef54cd98-fe6e-4721-b53e-8f6f46601061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19771005-a036-444f-848e-69e6b3a3f8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98, 0.94, 0.98])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clf = DecisionTreeClassifier(random_state=156)\n",
    "iris = load_iris()\n",
    "cross_val_score(df_clf, iris.data, iris.target, cv=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ee96a-c07f-4e73-a926-4e9b1ccaff85",
   "metadata": {},
   "source": [
    "## GridSearchCV : 교차 검증 + 최적 하이퍼 파라미터 튜닝\n",
    "\n",
    "> * 하이퍼 파라미터 : 머신러닝이 찾을 수 없는, 사람이 직접 넣어줘야 하는 값  \n",
    "> eg. K-fold 를 몇 개를 지정해줘야 하는지  \n",
    "> GridSearchCV는, K-fold의 fold 값 등의 옵션을 자동(최적)으로 지정해준다.  \n",
    "  \n",
    "> 하이퍼 파라미터  \n",
    "> 머신러닝에서는, 하이퍼 파라미터 값에 따라 모델의 성능이 많이 좌지우지된다.  \n",
    "> 그러므로 하이퍼 파라미터를 어떻게 설정해주느냐가 아주 중요하다.  \n",
    "  \n",
    "> GridSearchCV 는 최적화된 하이퍼 파라미터 값을 찾아 자동 적용한다.  \n",
    "> 하지만 최적의 값을 찾기 위해 여러 번 학습을 반복하므로, 시간이 오래 걸린다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf34f0cf-e0da-45bd-b0fb-17fd1d47dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62d8a660-cc48-4e0a-9dfb-8489208d2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'max_depth' : [1, 2,3],\n",
    "    'min_samples_split' : [2, 3],\n",
    "}\n",
    "\n",
    "# -> depth  * sample_split 횟수를 반복해, 최적의 분류/회귀값을 보이는 모델을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7185a39-41f1-4028-afca-a0cc84b0ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.2, random_state=121)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc460bef-dde0-421c-adfd-272a33a97f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(학습) 방법에 대한 설정\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_dtree = GridSearchCV(dtree, grid_param, cv=3, refit=True)\n",
    "# cv값 : 교차검증 횟수\n",
    "# refit : 가장 좋았던 학습방법을 최종 학습법으로 재 학습시킴\n",
    "\n",
    "# cv 값 * grid_param 값 인 18개의 결과값이 나올 것임\n",
    "# -> 이 중 가장 좋은 결과값을 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbf87d62-899a-4d90-8e2e-3e97642b70cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree.fit(X_train, y_train) # X_train과 y_train 데이터셋으로 학습을 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9789971-c970-4a2f-bffb-f5cfd5b9b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 1, 1, 1, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree.predict(X_test) # 학습된 모델을 토대로 X_test 데이터셋으로 테스트를 진행한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ec9ca17-fcf1-487d-bc26-9bd8a42b3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=3)\n",
      "\n",
      "\n",
      "{'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "0.975\n",
      "\n",
      "\n",
      "{'mean_fit_time': array([0.00033212, 0.        , 0.00033641, 0.00033196, 0.00033228,\n",
      "       0.00033243]), 'std_fit_time': array([0.00046968, 0.        , 0.00047575, 0.00046946, 0.00046991,\n",
      "       0.00047013]), 'mean_score_time': array([0.        , 0.        , 0.00033077, 0.        , 0.        ,\n",
      "       0.00033204]), 'std_score_time': array([0.        , 0.        , 0.00046777, 0.        , 0.        ,\n",
      "       0.00046957]), 'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'min_samples_split': 2}, {'max_depth': 1, 'min_samples_split': 3}, {'max_depth': 2, 'min_samples_split': 2}, {'max_depth': 2, 'min_samples_split': 3}, {'max_depth': 3, 'min_samples_split': 2}, {'max_depth': 3, 'min_samples_split': 3}], 'split0_test_score': array([0.7  , 0.7  , 0.925, 0.925, 0.975, 0.975]), 'split1_test_score': array([0.7, 0.7, 1. , 1. , 1. , 1. ]), 'split2_test_score': array([0.7 , 0.7 , 0.95, 0.95, 0.95, 0.95]), 'mean_test_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.975     ,\n",
      "       0.975     ]), 'std_test_score': array([1.11022302e-16, 1.11022302e-16, 3.11804782e-02, 3.11804782e-02,\n",
      "       2.04124145e-02, 2.04124145e-02]), 'rank_test_score': array([5, 5, 3, 3, 1, 1])}\n",
      "\n",
      "\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.000332      0.000470         0.000000        0.000000   \n",
      "1       0.000000      0.000000         0.000000        0.000000   \n",
      "2       0.000336      0.000476         0.000331        0.000468   \n",
      "3       0.000332      0.000469         0.000000        0.000000   \n",
      "4       0.000332      0.000470         0.000000        0.000000   \n",
      "5       0.000332      0.000470         0.000332        0.000470   \n",
      "\n",
      "  param_max_depth param_min_samples_split  \\\n",
      "0               1                       2   \n",
      "1               1                       3   \n",
      "2               2                       2   \n",
      "3               2                       3   \n",
      "4               3                       2   \n",
      "5               3                       3   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "0  {'max_depth': 1, 'min_samples_split': 2}              0.700   \n",
      "1  {'max_depth': 1, 'min_samples_split': 3}              0.700   \n",
      "2  {'max_depth': 2, 'min_samples_split': 2}              0.925   \n",
      "3  {'max_depth': 2, 'min_samples_split': 3}              0.925   \n",
      "4  {'max_depth': 3, 'min_samples_split': 2}              0.975   \n",
      "5  {'max_depth': 3, 'min_samples_split': 3}              0.975   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0                0.7               0.70         0.700000    1.110223e-16   \n",
      "1                0.7               0.70         0.700000    1.110223e-16   \n",
      "2                1.0               0.95         0.958333    3.118048e-02   \n",
      "3                1.0               0.95         0.958333    3.118048e-02   \n",
      "4                1.0               0.95         0.975000    2.041241e-02   \n",
      "5                1.0               0.95         0.975000    2.041241e-02   \n",
      "\n",
      "   rank_test_score  \n",
      "0                5  \n",
      "1                5  \n",
      "2                3  \n",
      "3                3  \n",
      "4                1  \n",
      "5                1  \n"
     ]
    }
   ],
   "source": [
    "print(grid_dtree.best_estimator_) # 가장 좋은 결과값 보였던 모델\n",
    "print(\"\\n\")\n",
    "print(grid_dtree.best_params_) # 가장 좋은 결과값 보였던 모델의 params\n",
    "print(\"\\n\")\n",
    "print(grid_dtree.best_score_) # 가장 좋은 결과값 보였던 모델의 score\n",
    "print(\"\\n\")\n",
    "print(grid_dtree.cv_results_) # 가장 좋은 결과값 보였던 모델에 대한 결과? 설명 -> 이걸 보기 좋게 데이터프레임으로 보자\n",
    "print(\"\\n\")\n",
    "print(pd.DataFrame(grid_dtree.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94502177-012b-4d12-ba74-1d66c3cc5c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 좋은 결과값을 보였던 모델을 실제 예측에 적용해보자\n",
    "\n",
    "pred = grid_dtree.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663ad1a-2fad-4bf6-9246-f1ac445c4284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
