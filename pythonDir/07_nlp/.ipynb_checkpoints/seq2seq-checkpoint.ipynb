{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "71620e98-f189-4bba-a106-933d1f7b9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "# EarlyStopping : \n",
    "# Model Chechpoint : \n",
    "\n",
    "from preprocess import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "59b5efb4-6135-4565-8cc2-11f474a00219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_' + string])\n",
    "    plt.legend([string], 'val_' + string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d838cff2-6fd0-4014-bdad-44aa5b2d1310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "\n",
    "DATA_IN_PATH = 'data_in/'\n",
    "DATA_OUT_PATH = 'data_out/'\n",
    "\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "\n",
    "DATA_CONFIGS = 'data_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "667382cb-f26e-4080-8946-19f806cdb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cd12894b-2f83-47f2-8fcf-439f3825babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS, 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS, 'rb'))\n",
    "\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c10c53f5-9597-487e-918f-76e1dcea7cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823 11823 11823\n"
     ]
    }
   ],
   "source": [
    "print(len(index_inputs), len(index_outputs), len(index_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e9171be8-1207-43e8-9c4e-7537a6ed51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq_kor'\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCH = 50\n",
    "UNITS = 1024\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0de3bce0-35df-452b-a3b0-69cb03a97c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['char2idx', 'idx2char', 'vocab_size', 'pad_symbol', 'std_symbol', 'end_symbol', 'unk_symbol'])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d2b1d53b-59a7-4bac-8405-9b70575cc487",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "std_index = prepro_configs['std_symbol']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "unk_index = prepro_configs['unk_symbol']\n",
    "\n",
    "vocab_size = prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6426870b-8cc5-40b2-bbdb-ca2e4c270488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()        # 상속 와 이렇게 쓰는거구나...\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')\n",
    "    \n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def initialize_hidden_state(self, inp):\n",
    "        return tf.zeros((tf.shape(inp)[0], self.enc_units))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "723e5ad2-4075-45fd-bec1-8babe4e764a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.W1(values) + self.W2(hidden_with_time_axis) # W1 : value에 관련된.. W2 : 쿼리에 관련된 것\n",
    "        score = self.V(tf.nn.tanh(score))\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9c251c93-b7b0-4761-87f3-df405c5110a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오... 층을 아래에서부터 쌓는 것도 좋네\n",
    "# 그러면 원하는 최종 결과물이 무엇인지를 보고, 그 결과가 나올 수 있게끔 필요한 것들과 양을 더 쉽게 정할 수 있을 듯\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.batch_sz = batch_sz\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences = True, return_state = True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1909648a-3f92-4b69-a43c-7e6605f5e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask를 쓰게 되는데..\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_ibject = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "                                                       \n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(read, pred)\n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype = pred.dtype), axis = -1)\n",
    "    pred *= mask\n",
    "    acc = train_accurach(real, pred)\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bb0bd9d6-3a20-4b5f-a591-d76b7279de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):\n",
    "        super(seq2seq, self).__init__()\n",
    "        \n",
    "        self.end_token_idx = end_token_idx\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz)\n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz)\n",
    "        \n",
    "    # 어떤 값을 주면, 학습을 진행해라 라는 함수\n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        predict_tokens = []\n",
    "        for t in range(0, tar.shape[1]): # tar.shape[1] -> 한 문장의 길이\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32) # float32 로 맞춤\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output) # _ : 출력값은 있으나, 쓰이지 않음\n",
    "            predictions = tf.dtypes.cast(predictions, tf.float32)\n",
    "            predict_tokens.append(predictions)\n",
    "        \n",
    "        return tf.stack(predict_tokens, axis=1)\n",
    "    \n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([char2idx[std_index]], 1) # STD에 해당하는 index를 반환, 그리고 차원 1개 추가\n",
    "        \n",
    "        predict_tokens = []\n",
    "        for t in ragne(0, MAX_SEQUENCE):\n",
    "            predictions, dec_hidden, dummy = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_token = tf.argmax(predictions[0]) # 어떤 단어인지 추려내는 단계 중\n",
    "            \n",
    "            if predict_token == self.end_token_idx:\n",
    "                break # 중지 : predict_token이 end_token의 인덱스와 같아지면\n",
    "                \n",
    "            predict_tokens.append(predict_token)\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims([predict_token], 0), tf.float32)\n",
    "        \n",
    "        \n",
    "        return tf.stack(predict_tokens, axis = 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7042b339-d58f-4489-b95b-368011440f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE, char2idx[end_index])\n",
    "model.compile(loss=loss, optimizer = tf.keras.optimizers.Adam(1e-3), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "413aeeeb-5785-4042-a737-250d11b83a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/__autograph_generated_filea1a2ezoa.py\", line 12, in tf__call\n        (enc_output, enc_hidden) = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(inp), ag__.ld(enc_hidden)), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"seq2seq_14\" \"                 f\"(type seq2seq).\n    \n    in user code:\n    \n        File \"/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/ipykernel_1431/2263536283.py\", line 14, in call  *\n            enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n    \n        TypeError: cannot unpack non-iterable NoneType object\n    \n    \n    Call arguments received by layer \"seq2seq_14\" \"                 f\"(type seq2seq):\n      • x=('tf.Tensor(shape=(2, 25), dtype=int64)', 'tf.Tensor(shape=(2, 25), dtype=int64)')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(checkpoint_path, monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mva_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                               save_weights_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m earlystop_callback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearlystop_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jh/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/__autograph_generated_filejfqz62tf.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/__autograph_generated_filea1a2ezoa.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m (inp, tar) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(x)\n\u001b[1;32m     11\u001b[0m enc_hidden \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39minitialize_hidden_state, (ag__\u001b[38;5;241m.\u001b[39mld(inp),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m (enc_output, enc_hidden) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mencoder, (ag__\u001b[38;5;241m.\u001b[39mld(inp), ag__\u001b[38;5;241m.\u001b[39mld(enc_hidden)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m dec_hidden \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(enc_hidden)\n\u001b[1;32m     14\u001b[0m predict_tokens \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/jongya/miniforge3/envs/jh/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/__autograph_generated_filea1a2ezoa.py\", line 12, in tf__call\n        (enc_output, enc_hidden) = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(inp), ag__.ld(enc_hidden)), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"seq2seq_14\" \"                 f\"(type seq2seq).\n    \n    in user code:\n    \n        File \"/var/folders/fn/b29w84gs71q01kp51x0ty8h80000gn/T/ipykernel_1431/2263536283.py\", line 14, in call  *\n            enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n    \n        TypeError: cannot unpack non-iterable NoneType object\n    \n    \n    Call arguments received by layer \"seq2seq_14\" \"                 f\"(type seq2seq):\n      • x=('tf.Tensor(shape=(2, 25), dtype=int64)', 'tf.Tensor(shape=(2, 25), dtype=int64)')\n"
     ]
    }
   ],
   "source": [
    "PATH = DATA_OUT_PATH + MODEL_NAME\n",
    "if not( os.path.isdir(PATH)):\n",
    "    os.makedirs(os.path.join(PATH))\n",
    "checkpoint_path = DATA_OUT_PATH + MODEL_NAME + './weights.h5'\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor = 'va_accuracy', verbose = 1, save_best_only = True,\n",
    "                              save_weights_only = True)\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets,\n",
    "                    batch_size = BATCH_SIZE, epochs = EPOCH,\n",
    "                    validation_split = VALIDATION_SPLIT, callbacks = [earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a38614-2da4-4d7d-8036-2a73c99a031a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
