{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dde943-cb01-4aea-93e2-4e9fc383082d",
   "metadata": {},
   "source": [
    "# 강사님 생각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9b81a-fbef-43f1-ab9a-40b1d92e99cd",
   "metadata": {},
   "source": [
    "## 좋은 회사란??  \n",
    "* 세미나를 많이 하는 회사라고 생각한다.  \n",
    "* 이는, 계속 성장하려는 회사라는 것이고  \n",
    "* 직원들이 공부할 수 있게 하는 회사라는 것이다.  \n",
    "* 규모의 문제가 아님  \n",
    "* 계속 외부 인재를 통한 인사이트 업그레이드는 불가능하다.  \n",
    "* 내부 인재들에게 성장하게 하고, 이를 세미나를 통해 발표하는 것. 아주 바람직하다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aacb0c-4c38-430c-9afe-35b9ed0df094",
   "metadata": {},
   "source": [
    "# RNN, LSTM, GRU?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d6930-0d93-4c36-b1ed-badc078205c8",
   "metadata": {},
   "source": [
    "* LSTM, GRU는 RNN의 파생형\n",
    "* Seq2seq : 문장 to 문장. RNN을 사용하는 개념이다. 이를 통해 번역이나 챗봇, 요약 등이 가능하다.  \n",
    "* 그런데 하다 보면, RNN이 필요가 없고 Transformer 구조로 간다. RNN이 아닌, Attention의 개념으로 가게 된다.??? 이게 무엇???  \n",
    "* 그러면 우리가 매번 학습을 시켜야 하나? 그럴 필요가 없음. 이에 pre-trained(fine-tuning) 사전학습 된 것을 전이학습으로 사용하는 것으로 충분하게 된다.  \n",
    "* 여기서 나오는 것들이 BERT, GPT(챗 GPT로 알려진) 것들이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531dc35-1c65-45be-b9e0-72a6a2ab78eb",
   "metadata": {},
   "source": [
    "* speach 음성인식 쪽은 이미 많이 개발이 되었고, 더이상 더 좋은 기술이 필요가 없을 정도이다. 라고 강사님은 본다.  \n",
    "* 그래서 굳이 speach를 진행해야할까... 라는 생각이 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87853d3-a8b9-4380-8e25-f410ba14d0c7",
   "metadata": {},
   "source": [
    "## RNN으로 가사 분석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "731b3e82-18d8-4100-8f52-dea01406b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''저 별을 따다가 니 귀에 걸어주고파\n",
    "저 달 따다가 니 목에 걸어주고파\n",
    "세상 모든 좋은 것만 해주고 싶은\n",
    "이런 내 맘을 그댄 아나요.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2170828-61bb-434e-bf5d-9739f9b2bad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n저? -> '별을' 을 출력\\n저 별을? -> '따다가' 를 출력\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 목표\n",
    "# 위 텍스트를 학습시켰을 때\n",
    "\n",
    "'''\n",
    "저? -> '별을' 을 출력\n",
    "저 별을? -> '따다가' 를 출력\n",
    "'''\n",
    "\n",
    "# 이런 식으로, 운을 띄웠을 때 그 다음 문장을 예측하거나 추천할 수 있는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de63e08-606e-4f9f-9c92-65104df825f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8be0569-4155-4f16-9cb6-9ea71b0d5445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'저': 1,\n",
       " '따다가': 2,\n",
       " '니': 3,\n",
       " '걸어주고파': 4,\n",
       " '별을': 5,\n",
       " '귀에': 6,\n",
       " '달': 7,\n",
       " '목에': 8,\n",
       " '세상': 9,\n",
       " '모든': 10,\n",
       " '좋은': 11,\n",
       " '것만': 12,\n",
       " '해주고': 13,\n",
       " '싶은': 14,\n",
       " '이런': 15,\n",
       " '내': 16,\n",
       " '맘을': 17,\n",
       " '그댄': 18,\n",
       " '아나요': 19}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 인덱싱\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts([text])\n",
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "284c98e7-27f0-4081-b5df-b06d2930d493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size\n",
    "vocab_size = len(tok.word_index) + 1 # +1 : zero padding용\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62e700e9-f7f5-4f63-90e7-0672142180dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 5, 2],\n",
       " [1, 5, 2, 3],\n",
       " [1, 5, 2, 3, 6],\n",
       " [1, 5, 2, 3, 6, 4],\n",
       " [1, 7],\n",
       " [1, 7, 2],\n",
       " [1, 7, 2, 3],\n",
       " [1, 7, 2, 3, 8],\n",
       " [1, 7, 2, 3, 8, 4],\n",
       " [9, 10],\n",
       " [9, 10, 11],\n",
       " [9, 10, 11, 12],\n",
       " [9, 10, 11, 12, 13],\n",
       " [9, 10, 11, 12, 13, 14],\n",
       " [15, 16],\n",
       " [15, 16, 17],\n",
       " [15, 16, 17, 18],\n",
       " [15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장으로 나눈 후\n",
    "# 각 문장이 전개되는 순서가 담긴 리스트 만들기\n",
    "\n",
    "seq_list = []\n",
    "\n",
    "for sentence in text.split('\\n'):\n",
    "    res = tok.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1, len(res)):\n",
    "        seq = res[:i+1]\n",
    "        seq_list.append(seq)\n",
    "\n",
    "seq_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23526ab-b746-4926-b00e-3eb4a8f50a5c",
   "metadata": {},
   "source": [
    "* 위 코드 결과값 설명\n",
    "\n",
    "[1, 5], 저 별을  \n",
    "[1, 5, 2], 저 별을 따다가  \n",
    "[1, 5, 2, 3], 저 별을 따다가 니  \n",
    "[1, 5, 2, 3, 6], 저 별을 따다가 니 귀에  \n",
    "[1, 5, 2, 3, 6, 4], 저 별을 따다가 니 귀에 걸어주고파  \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01d79005-cd64-4548-9b2e-5127e657a80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  1,  5],\n",
       "       [ 0,  0,  0,  1,  5,  2],\n",
       "       [ 0,  0,  1,  5,  2,  3],\n",
       "       [ 0,  1,  5,  2,  3,  6],\n",
       "       [ 1,  5,  2,  3,  6,  4],\n",
       "       [ 0,  0,  0,  0,  1,  7],\n",
       "       [ 0,  0,  0,  1,  7,  2],\n",
       "       [ 0,  0,  1,  7,  2,  3],\n",
       "       [ 0,  1,  7,  2,  3,  8],\n",
       "       [ 1,  7,  2,  3,  8,  4],\n",
       "       [ 0,  0,  0,  0,  9, 10],\n",
       "       [ 0,  0,  0,  9, 10, 11],\n",
       "       [ 0,  0,  9, 10, 11, 12],\n",
       "       [ 0,  9, 10, 11, 12, 13],\n",
       "       [ 9, 10, 11, 12, 13, 14],\n",
       "       [ 0,  0,  0,  0, 15, 16],\n",
       "       [ 0,  0,  0, 15, 16, 17],\n",
       "       [ 0,  0, 15, 16, 17, 18],\n",
       "       [ 0, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero_padding 진행\n",
    "\n",
    "max_len = max(len(sent) for sent in seq_list)\n",
    "max_len # 결과값 : 6\n",
    "\n",
    "seq_padded = pad_sequences(seq_list, maxlen=max_len)\n",
    "seq_padded # 일반적으로 패딩 0은 값의 앞쪽에 위치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa46ae33-4aaa-4671-9e92-37cd2d50d845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  1,  5],\n",
       "        [ 0,  0,  1,  5,  2],\n",
       "        [ 0,  1,  5,  2,  3],\n",
       "        [ 1,  5,  2,  3,  6],\n",
       "        [ 0,  0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  1,  7],\n",
       "        [ 0,  0,  1,  7,  2],\n",
       "        [ 0,  1,  7,  2,  3],\n",
       "        [ 1,  7,  2,  3,  8],\n",
       "        [ 0,  0,  0,  0,  9],\n",
       "        [ 0,  0,  0,  9, 10],\n",
       "        [ 0,  0,  9, 10, 11],\n",
       "        [ 0,  9, 10, 11, 12],\n",
       "        [ 9, 10, 11, 12, 13],\n",
       "        [ 0,  0,  0,  0, 15],\n",
       "        [ 0,  0,  0, 15, 16],\n",
       "        [ 0,  0, 15, 16, 17],\n",
       "        [ 0, 15, 16, 17, 18]]),\n",
       " array([ 5,  2,  3,  6,  4,  7,  2,  3,  8,  4, 10, 11, 12, 13, 14, 16, 17,\n",
       "        18, 19]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X와 y 나누기\n",
    "\n",
    "X = seq_padded[:, :-1] # X는 각 리스트에서 최종 단어 하나를 뺀 전부\n",
    "y = seq_padded[:, -1] # y는 각 리스트의 가장 마지막 값\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4928d564-0c73-4e02-ab9c-97376ffff40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y 원핫인코딩\n",
    "y_hot = to_categorical(y, num_classes = vocab_size)\n",
    "y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eec1f3cf-2ec6-406e-bf44-ae3d8947ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 만들기\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 10), # 이만큼의 vocab_size가 들어갈거야, 그리고 각 단어들을 10개 차원으로 나눠서 (분석?) 해줘\n",
    "    SimpleRNN(32),\n",
    "    Dense(vocab_size, activation='softmax')]) # 원핫인코딩이므로 소프트맥스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc60524e-8919-43ae-b241-a41cf9e1874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 10)          200       \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                1376      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,236\n",
      "Trainable params: 2,236\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 둘러보기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1228a22a-65bd-46eb-b362-6c0e56b4ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', # 로스는 어떻게 할거냐\n",
    "              optimizer = 'adam', # 로스는 어떻게 찾아갈거냐\n",
    "              metrics = ['accuracy']) # 성능 측정은 어떻게 할 거냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78ff2231-0b7e-4ce2-a87b-69bcdf01f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17856\\3575918653.py\", line 2, in <module>\n      history = model.fit(X, y_hot, epochs = 200, verbose=1)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [19,20] and labels shape [380]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_6397]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\user\\anaconda3\\envs\\sesac_jh\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17856\\3575918653.py\", line 2, in <module>\n      history = model.fit(X, y_hot, epochs = 200, verbose=1)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [19,20] and labels shape [380]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_6397]"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "history = model.fit(X, y_hot, epochs = 1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4adf7304-3705-4c41-8687-9d8e204e1979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0],\n",
       "        [15, 16, 17, 18]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측하고 싶은 텍스트 인코딩\n",
    "start_text = '이런 내 맘을 그댄'\n",
    "encoded = tok.texts_to_sequences([start_text])\n",
    "encoded\n",
    "\n",
    "# 예측하고 싶은 텍스트 패딩\n",
    "padded = pad_sequences([encoded], maxlen = max_len)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcc7b7-f6c3-47b1-a3ea-50fe56485d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(padded, verbose=1)\n",
    "res.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
